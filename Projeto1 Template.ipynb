{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Eduardo Machado de Oliveira\n",
    "\n",
    "Nome: Henrique Leite dos Santos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\henri\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Aulas\\Aulas 2¬∫ Semestre\\CDados\\Projeto Arrumado\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O autor escreve sua experi√™ncia pessoal do que...</td>\n",
       "      <td>Livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Partindo do fundamentalismo crist√£o e de ideia...</td>\n",
       "      <td>Livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N√£o li o livro ainda, ent√£o a avalia√ß√£o refere...</td>\n",
       "      <td>Livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N√£o acompanho o youtube, talvez seja a falta d...</td>\n",
       "      <td>Livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O livro √© apenas uma motiva√ß√£o, muito superfic...</td>\n",
       "      <td>Livro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem Target\n",
       "0  O autor escreve sua experi√™ncia pessoal do que...  Livro\n",
       "1  Partindo do fundamentalismo crist√£o e de ideia...  Livro\n",
       "2  N√£o li o livro ainda, ent√£o a avalia√ß√£o refere...  Livro\n",
       "3  N√£o acompanho o youtube, talvez seja a falta d...  Livro\n",
       "4  O livro √© apenas uma motiva√ß√£o, muito superfic...  Livro"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.read_excel('dados_treino.xlsx')\n",
    "train_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabei de comprar O Hobbit (vers√£o Kindle) par...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O di√°rio de Anne Frank trata-se de uma farsa, ...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N√£o achei muita gra√ßa n√£o üëéüèª</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ol√°, Recebi uma notifica√ß√£o por email que n√£o ...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Sapiens: uma breve hist√≥ria da humanidade rea...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  Target\n",
       "0  Acabei de comprar O Hobbit (vers√£o Kindle) par...  amazon\n",
       "1  O di√°rio de Anne Frank trata-se de uma farsa, ...   livro\n",
       "2                       N√£o achei muita gra√ßa n√£o üëéüèª   livro\n",
       "3  Ol√°, Recebi uma notifica√ß√£o por email que n√£o ...  amazon\n",
       "4  \"Sapiens: uma breve hist√≥ria da humanidade rea...   livro"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw = pd.read_excel('dados_teste.xlsx')\n",
    "test_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza das mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Fun√ß√£o que limpa as pontua√ß√µes das mensagens\n",
    "def clean(text):\n",
    "    punctuation = '[¬¥\"!-.:?;$'']'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o autor escreve sua experi√™ncia pessoal do que...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partindo do fundamentalismo crist√£o e de ideia...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n√£o li o livro ainda ent√£o a avalia√ß√£o referes...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n√£o acompanho o youtube talvez seja a falta de...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o livro √© apenas uma motiva√ß√£o muito superfici...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem Target\n",
       "0  o autor escreve sua experi√™ncia pessoal do que...  livro\n",
       "1  partindo do fundamentalismo crist√£o e de ideia...  livro\n",
       "2  n√£o li o livro ainda ent√£o a avalia√ß√£o referes...  livro\n",
       "3  n√£o acompanho o youtube talvez seja a falta de...  livro\n",
       "4  o livro √© apenas uma motiva√ß√£o muito superfici...  livro"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpando a base de dados treino:\n",
    "dados_train = []\n",
    "\n",
    "# Limpeza das mensagens da base de dados TREINO\n",
    "for i in range(len(train_raw)):\n",
    "    mensagem_raw = train_raw.Mensagem[i]\n",
    "    mensagem = clean(mensagem_raw)\n",
    "    target = train_raw.Target[i]\n",
    "    \n",
    "    dados_train.append([mensagem.lower(), target.lower()])\n",
    "    \n",
    "train = pd.DataFrame(dados_train, columns=['Mensagem','Target'])\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acabei de comprar o hobbit vers√£o kindle para ...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o di√°rio de anne frank tratase de uma farsa um...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n√£o achei muita gra√ßa n√£o üëéüèª</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ol√° recebi uma notifica√ß√£o por email que n√£o f...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sapiens uma breve hist√≥ria da humanidade realm...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  Target\n",
       "0  acabei de comprar o hobbit vers√£o kindle para ...  amazon\n",
       "1  o di√°rio de anne frank tratase de uma farsa um...   livro\n",
       "2                       n√£o achei muita gra√ßa n√£o üëéüèª   livro\n",
       "3  ol√° recebi uma notifica√ß√£o por email que n√£o f...  amazon\n",
       "4  sapiens uma breve hist√≥ria da humanidade realm...   livro"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpando a base de dados teste:\n",
    "dados_test = []\n",
    "\n",
    "# Limpeza das mensagens da base de dados TESTE\n",
    "for i in range(len(test_raw)):\n",
    "    mensagem_raw = test_raw.Mensagem[i]\n",
    "    mensagem = clean(mensagem_raw)\n",
    "    target = test_raw.Target[i]\n",
    "    \n",
    "    dados_test.append([mensagem.lower(), target.lower()])\n",
    "    \n",
    "test = pd.DataFrame(dados_test, columns=['Mensagem','Target'])\n",
    "\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outros m√©todos de limpeza\n",
    "\n",
    "Poderia ter sido aplicado, tamb√©m, outro m√©todo para limpeza das mensagens, como remo√ß√£o de stop-words ou lemmatization.\n",
    "\n",
    "No caso das stop-words, um arquivo contendo todas essas palavras deveria ser baixado e um loop de remo√ß√£o dessas palavras\n",
    "deveria ser criado para limpar as mensagens originais.\n",
    "\n",
    "Um exemplo de remo√ß√£o de stop-words:\n",
    "\n",
    "\"Ao caminhar pelo parque, observei muitos p√°ssaros pequenos voando entre as √°rvores.\" | Com stop-words\n",
    "\n",
    "\"Caminhar parque, observei p√°ssaros pequenos voando √°rvores.\" | Sem stop-words\n",
    "\n",
    "<br>\n",
    "\n",
    "J√° a lemmatization, seguiria uma mesma estrutura s√≥ que um pouco diferente. O processo consiste em transformar as plavra sem \"lemas\", ou seja, uma forma reduzida. Por esse m√©todo, as plavras \"corrida\", \"correndo\", \"correu\" e \"corre\" seriam reduzidas ao lema \"correr\", o que simplificaria a an√°lise do texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu assunto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets (Target).\n",
    "\n",
    "Ao definir a vari√°vel Target do projeto, nos colocamos na posi√ß√£o de um empregado da Amazon que deseja saber quais reclama√ß√µes s√£o em rela√ß√£o √† entrega dos livros ou √† plataforma Amazon (pre√ßos, entrega, etc.) e quais s√£o reclama√ß√µes relacionadas ao conte√∫do dos livros, tamb√©m inclu√≠mos uma target \"Outro\" para casos que n√£o se aplicam √† nenhum dos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "livro     0.796667\n",
       "amazon    0.183333\n",
       "outro     0.020000\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_target = train.Target.value_counts(normalize=True)\n",
    "\n",
    "P_livro = P_target[0]\n",
    "P_amazon = P_target[1]\n",
    "P_outro = P_target[2]\n",
    "\n",
    "# Probabilidades de cada target dentro da base de dados\n",
    "P_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todas as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lista de todas as palavras\n",
    "\n",
    "todas_palavras_df = ''\n",
    "\n",
    "for i in range(len(test.Mensagem)):\n",
    "    msg = str(test.Mensagem[i])\n",
    "    todas_palavras_df += msg + ' '\n",
    "\n",
    "# Todas as palavras do DataFrame separadas em uma lista\n",
    "todas_palavras_df = todas_palavras_df.split()\n",
    "\n",
    "# Series de todas as palavras\n",
    "serie_df = pd.Series(todas_palavras_df)\n",
    "tabela_df = serie_df.value_counts()\n",
    "\n",
    "# Todas as palavras diferentes\n",
    "palavras_diferentes = len(tabela_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas as palavras em \"Amazon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de todas as palavras na categoria Amazon\n",
    "\n",
    "mensagens_amazon = train.loc[train['Target']=='amazon', ['Mensagem']]\n",
    "mensagens_amazon = mensagens_amazon.reset_index(drop=True)\n",
    "\n",
    "todas_palavras_amazon = ''\n",
    "\n",
    "for i in range(len(mensagens_amazon['Mensagem'])):\n",
    "    msg = str(mensagens_amazon.Mensagem[i])\n",
    "    todas_palavras_amazon += msg + ' '\n",
    "    \n",
    "# Todas as palavras da target \"amazon\" separadas em uma lista\n",
    "todas_palavras_amazon = todas_palavras_amazon.split()\n",
    "\n",
    "# Series de todas as palavras da target \"amazon\"\n",
    "serie_amazon = pd.Series(todas_palavras_amazon)\n",
    "tabela_amazon = serie_amazon.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas as palavras em \"Livro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de todas as palavras na categoria Livros\n",
    "\n",
    "mensagens_livro = train.loc[train['Target']=='livro', ['Mensagem']]\n",
    "mensagens_livro = mensagens_livro.reset_index(drop=True)\n",
    "\n",
    "todas_palavras_livro = ''\n",
    "\n",
    "for i in range(len(mensagens_livro['Mensagem'])):\n",
    "    msg = str(mensagens_livro.Mensagem[i])\n",
    "    todas_palavras_livro += msg + ' '\n",
    "    \n",
    "# Todas as palavras da target \"livro\" separadas em uma lista\n",
    "todas_palavras_livro = todas_palavras_livro.split()\n",
    "\n",
    "# Series de todas as palavras da target \"livro\"\n",
    "serie_livro = pd.Series(todas_palavras_livro)\n",
    "tabela_livro = serie_livro.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas as palavras em \"Outro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de todas as palavras na categoria Outros\n",
    "\n",
    "mensagens_outro = train.loc[train['Target']=='outro', ['Mensagem']]\n",
    "mensagens_outro = mensagens_outro.reset_index(drop=True)\n",
    "\n",
    "todas_palavras_outro = ''\n",
    "\n",
    "for i in range(len(mensagens_outro['Mensagem'])):\n",
    "    msg = str(mensagens_outro.Mensagem[i])\n",
    "    todas_palavras_outro += msg + ' '\n",
    "    \n",
    "# Todas as palavras da target \"outro\" separadas em uma lista\n",
    "todas_palavras_outro = todas_palavras_outro.split()\n",
    "\n",
    "# Series de todas as palavras da target \"livro\"\n",
    "serie_outro = pd.Series(todas_palavras_outro)\n",
    "tabela_outro = serie_outro.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predi√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acabei de comprar o hobbit vers√£o kindle para ...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o di√°rio de anne frank tratase de uma farsa um...</td>\n",
       "      <td>livro</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n√£o achei muita gra√ßa n√£o üëéüèª</td>\n",
       "      <td>livro</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ol√° recebi uma notifica√ß√£o por email que n√£o f...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sapiens uma breve hist√≥ria da humanidade realm...</td>\n",
       "      <td>livro</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  Target Predi√ß√£o\n",
       "0  acabei de comprar o hobbit vers√£o kindle para ...  amazon   amazon\n",
       "1  o di√°rio de anne frank tratase de uma farsa um...   livro   amazon\n",
       "2                       n√£o achei muita gra√ßa n√£o üëéüèª   livro    livro\n",
       "3  ol√° recebi uma notifica√ß√£o por email que n√£o f...  amazon   amazon\n",
       "4  sapiens uma breve hist√≥ria da humanidade realm...   livro    livro"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(test['Mensagem'])):\n",
    "    msg = test.Mensagem[i]\n",
    "    palavras = msg.split()\n",
    "    alpha = 1\n",
    "    \n",
    "    amazon_parcial = 1\n",
    "    livro_parcial = 1\n",
    "    outro_parcial = 1\n",
    "    \n",
    "    \n",
    "    # A multiplica√ß√£o por 1000 das parciais vieram para \"Frear\" a velocidade com que essas probabilidades ficam muito pequenas\n",
    "    # J√° que o Python estava arredondando para 0, o que impossibilitava uma an√°lise correta;\n",
    "    # Essa multiplica√ß√£o n√£o altera o resultado final, j√° que todas as parcelas s√£o multiplicadas pelo mesmo fator.\n",
    "\n",
    "\n",
    "    for palavra in palavras:\n",
    "        if palavra not in todas_palavras_amazon:\n",
    "            amazon_parcial *= ((0 + alpha)/(sum(tabela_amazon) + palavras_diferentes))*1000\n",
    "        else:\n",
    "            amazon_parcial *= ((tabela_amazon[palavra] + alpha)/(sum(tabela_amazon) + palavras_diferentes))*1000\n",
    "            \n",
    "            \n",
    "        if palavra not in todas_palavras_livro:\n",
    "            livro_parcial *= ((0 + alpha)/(sum(tabela_livro) + palavras_diferentes))*1000\n",
    "        else:\n",
    "            livro_parcial *= ((tabela_livro[palavra] + alpha)/(sum(tabela_livro) + palavras_diferentes))*1000\n",
    "            \n",
    "        \n",
    "        if palavra not in todas_palavras_outro:\n",
    "            outro_parcial *= ((0 + alpha)/(sum(tabela_outro) + palavras_diferentes))*1000\n",
    "        else:\n",
    "            outro_parcial *= ((tabela_outro[palavra] + alpha)/(sum(tabela_outro) + palavras_diferentes))*1000\n",
    "            \n",
    "    if outro_parcial > amazon_parcial and outro_parcial > livro_parcial:\n",
    "        test.loc[i, 'Predi√ß√£o'] = 'outro'\n",
    "    elif amazon_parcial > livro_parcial and amazon_parcial > outro_parcial:\n",
    "        test.loc[i, 'Predi√ß√£o'] = 'amazon'\n",
    "    elif livro_parcial > amazon_parcial and livro_parcial > outro_parcial:\n",
    "        test.loc[i, 'Predi√ß√£o'] = 'livro'\n",
    "\n",
    "        \n",
    "# DataFrame TESTE com a coluna das predi√ß√µes (classifica√ß√µes do classificador)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Target</th>\n",
       "      <th>amazon</th>\n",
       "      <th>livro</th>\n",
       "      <th>outro</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predi√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amazon</th>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>livro</th>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>46</td>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Target    amazon  livro  outro  All\n",
       "Predi√ß√£o                           \n",
       "amazon        41     20      3   64\n",
       "livro          5    129      2  136\n",
       "All           46    149      5  200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_x_predicao = pd.crosstab(test['Predi√ß√£o'], test['Target'], normalize = False, margins = True)\n",
    "\n",
    "# Tabela cruzada das classifica√ß√µes feitas pelo classificador e as classifica√ß√µes originais\n",
    "real_x_predicao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a acertividade do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de acerto (acur√°cia) √© de: 85.00%\n",
      "A probabilidade de verdadeiro positivo √© de: 89.13%\n",
      "A probabilidade de falso positivo √© de: 35.94%\n",
      "A probabilidade de verdadeiro negativo √© de: 85.06%\n",
      "A probabilidade de falso negativo √© de: 10.87%\n"
     ]
    }
   ],
   "source": [
    "# Calculando a acur√°cia\n",
    "if 'outro' not in test.Predi√ß√£o:\n",
    "    P_acerto = (real_x_predicao['amazon']['amazon'] + real_x_predicao['livro']['livro'] + 0)/real_x_predicao['All']['All']\n",
    "else:\n",
    "    P_acerto = (real_x_predicao['amazon']['amazon'] + real_x_predicao['livro']['livro'] + real_x_predicao['outro']['outro'])/real_x_predicao['All']['All']\n",
    "\n",
    "print(f'A probabilidade de acerto (acur√°cia) √© de: {P_acerto*100:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "# Calculando falsos positivos, falsos negativos, verdadeiros positivos e verdadeiros negativos:\n",
    "# Para essa etapa, consideramos \"AMAZON\" como relevante e \"LIVRO\" e \"OUTRO\" como irrelevante:\n",
    "\n",
    "\n",
    "# Verdadeiro positivos:\n",
    "# Mensagens da tag \"AMAZON\", classificadas como \"AMAZON\"\n",
    "P_V_pos = real_x_predicao['amazon']['amazon']/real_x_predicao['amazon']['All']\n",
    "print(f'A probabilidade de verdadeiro positivo √© de: {P_V_pos*100:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "# Falso positivo:\n",
    "# Mensagens das tags \"LIVRO\" e \"OUTRO\", classificadas como \"AMAZON\"\n",
    "P_F_pos = (real_x_predicao['livro']['amazon'] + real_x_predicao['outro']['amazon'])/real_x_predicao['All']['amazon']\n",
    "print(f'A probabilidade de falso positivo √© de: {P_F_pos*100:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "# Verdadeiro negativo:\n",
    "# Mensagens das tags \"LIVRO\" e \"OUTRO\", classificadas como \"LIVRO\" ou \"OUTRO\"\n",
    "if 'outro' not in test.Predi√ß√£o:\n",
    "    P_V_neg = (real_x_predicao['livro']['livro'] + real_x_predicao['outro']['livro'] + 0 + 0)/(real_x_predicao['livro']['All'] + real_x_predicao['outro']['All'])\n",
    "else:\n",
    "    P_V_neg = (real_x_predicao['livro']['livro'] + real_x_predicao['outro']['livro'] + real_x_predicao['livro']['outro'] + real_x_predicao['outro']['outro'])/(real_x_predicao['livro']['All'] + real_x_predicao['outro']['All'])\n",
    "\n",
    "print(f'A probabilidade de verdadeiro negativo √© de: {P_V_neg*100:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "# Falso negativo:\n",
    "# Mensagens da tag \"AMAZON\", classificadas como \"OUTRO\" ou \"LIVRO\"\n",
    "if 'outro' not in test.Predi√ß√£o:\n",
    "    P_F_neg = (real_x_predicao['amazon']['livro'] + 0)/real_x_predicao['amazon']['All']\n",
    "else:\n",
    "    P_F_neg = (real_x_predicao['amazon']['livro'] + real_x_predicao['amazon']['outro'])/real_x_predicao['amazon']['All']\n",
    "    \n",
    "print(f'A probabilidade de falso negativo √© de: {P_F_neg*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerando o contexto dado ao in√≠cio do notebook\n",
    "*Ao definir a vari√°vel Target do projeto, nos colocamos na posi√ß√£o de um empregado da Amazon que deseja saber quais reclama√ß√µes s√£o em rela√ß√£o √† entrega dos livros ou √† plataforma Amazon (pre√ßos, entrega, etc.) e quais s√£o reclama√ß√µes relacionadas ao conte√∫do dos livros.*\n",
    "\n",
    "O que justifica a nossa vari√°vel relevante ser \"AMAZON\" e a irrelevante ser o conjunto \"LIVRO\" e \"OUTRO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 ‚Äì Acur√°cia:\n",
    "\n",
    "O classificador, esteve correto na classifica√ß√£o de 85% das mensagens. Isso indica uma precis√£o geral do classificador, mas n√£o diz muito a respeito da sua sensibilidade ou especificidade, para isso, precisamos analisar as probabilidades de verdadeiros positivos e verdadeiros negativos;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 ‚Äì Verdadeiros positivos (Sensibilidade):\n",
    "\n",
    "A probabilidade de verdadeiros positivos foi de 89.13%. Isso demonstra que o classificador consegue identificar muito bem mensagens da que s√£o realmente da tag \"AMAZON\", em rela√ß√£o ao total real de mensagens dessa tag. Com um valor t√£o alto, o classificador parece ser eficaz na identifica√ß√£o de casos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 ‚Äì Falso positivo:\n",
    "\n",
    "A probabilidade de falso positivo foi de 35.94%. Isso indica a taxa de erro do classificador ao classificar incorretamente casos negativos como positivos, ou seja, mensagens originalmente das tag ‚ÄúLIVRO‚Äù e ‚ÄúOUTRO‚Äù como sendo da tag ‚ÄúAMAZON‚Äù. Esse valor est√° relativamente alto, mostrando que o classificador est√° cometendo muitos erros desse tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 ‚Äì Verdadeiro negativo (Especificidade):\n",
    "\n",
    "A probabilidade de verdadeiro negativo foi de 85.06%. Isso demonstra que o classificador consegue identificar corretamente as mensagens direcionadas √†s tags ‚ÄúLIVRO‚Äù e ‚ÄúOUTRO‚Äù, em rela√ß√£o ao total real de mensagens dessas tags. Com um valor t√£o alto, o classificador parece ser eficaz na identifica√ß√£o de casos realmente negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 ‚Äì Falso negativo:\n",
    "\n",
    "A probabilidade de falso negativo foi de 10.87%. Isso indica a chance de o classificador classificar incorretamente casos positivos como negativos, ou seja, mensagens que originalmente eram da tag ‚ÄúAMAZON‚Äù como sendo de outra tag. Com um valor relativamente baixo, conclu√≠mos que o classificador est√° cometendo poucos erros desse tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Mensagens de dupla nega√ß√£o ou sarc√°sticas\n",
    "\n",
    "No contexto de mensagens que cont√©m dupla nega√ß√£o ou sarcasmo, o classificador Naive-Byas com certeza n√£o √© a melhor ferramente, j√° que interpreta cada mensagem (independente da conota√ß√£o) a partir de sua probabilidade dentro da base de dados TREINO, desconsiderando completamente qualquer artif√≠cio lingu√≠stico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Plano de expans√£o:\n",
    "1 - Para melhorar a acur√°cia, sensibilidade e especificidade do classificador, seria necess√°rio ter uma base de dados significativamente maior para que o classificador pudesse ter mais informa√ß√£o na hora de calcular as probabilidades;\n",
    "\n",
    "2 - Melhorar o tratamento do texto tamb√©m √© uma boa op√ß√£o, utilizando t√©cnicas de remo√ß√£o de stop-words, lemmatization entre outras. Essa melhora no tratamento aumentaria a efic√°cia na hora da classifica√ß√£o das mensagens.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Por que financiar o projeto?\n",
    "O classificador pode ser uma ferramenta muito √∫til para automatizar a classifica√ß√£o das mensagens. Essa automatiza√ß√£o melhoraria a qualidade na tomada de decis√µes da empresa o que, consequentemente, aumentaria os lucros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos reviews entre Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabei de comprar O Hobbit (vers√£o Kindle) par...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O di√°rio de Anne Frank trata-se de uma farsa, ...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N√£o achei muita gra√ßa n√£o üëéüèª</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ol√°, Recebi uma notifica√ß√£o por email que n√£o ...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Sapiens: uma breve hist√≥ria da humanidade rea...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Bom quanto a Qualidade dos livros est√£o em per...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>H√° alguns dias atr√°s adquiri um produto na Ama...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Comecei a leitura hoje e estou abismado com a ...</td>\n",
       "      <td>Livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Concordo com outras avalia√ß√µes feitas, entre o...</td>\n",
       "      <td>Livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Imposs√≠vel ler, j√° pedi v√°rias vezes, n√£o sei ...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem  Target\n",
       "0    Acabei de comprar O Hobbit (vers√£o Kindle) par...  amazon\n",
       "1    O di√°rio de Anne Frank trata-se de uma farsa, ...   livro\n",
       "2                         N√£o achei muita gra√ßa n√£o üëéüèª   livro\n",
       "3    Ol√°, Recebi uma notifica√ß√£o por email que n√£o ...  amazon\n",
       "4    \"Sapiens: uma breve hist√≥ria da humanidade rea...   livro\n",
       "..                                                 ...     ...\n",
       "495  Bom quanto a Qualidade dos livros est√£o em per...  Amazon\n",
       "496  H√° alguns dias atr√°s adquiri um produto na Ama...  Amazon\n",
       "497  Comecei a leitura hoje e estou abismado com a ...   Livro\n",
       "498  Concordo com outras avalia√ß√µes feitas, entre o...   Livro\n",
       "499  Imposs√≠vel ler, j√° pedi v√°rias vezes, n√£o sei ...  Amazon\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Novo dataframe que junta as mensagens da base TREINO e TESTE\n",
    "frames = [test_raw, train_raw]\n",
    "todos_raw = pd.concat(frames)\n",
    "todos_raw = todos_raw.reset_index(drop=True)\n",
    "\n",
    "todos_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acabei de comprar o hobbit vers√£o kindle para ...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o di√°rio de anne frank tratase de uma farsa um...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n√£o achei muita gra√ßa n√£o üëéüèª</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ol√° recebi uma notifica√ß√£o por email que n√£o f...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sapiens uma breve hist√≥ria da humanidade realm...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>bom quanto a qualidade dos livros est√£o em per...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>h√° alguns dias atr√°s adquiri um produto na ama...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>comecei a leitura hoje e estou abismado com a ...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>concordo com outras avalia√ß√µes feitas entre ou...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>imposs√≠vel ler j√° pedi v√°rias vezes n√£o sei ma...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem  Target\n",
       "0    acabei de comprar o hobbit vers√£o kindle para ...  amazon\n",
       "1    o di√°rio de anne frank tratase de uma farsa um...   livro\n",
       "2                         n√£o achei muita gra√ßa n√£o üëéüèª   livro\n",
       "3    ol√° recebi uma notifica√ß√£o por email que n√£o f...  amazon\n",
       "4    sapiens uma breve hist√≥ria da humanidade realm...   livro\n",
       "..                                                 ...     ...\n",
       "495  bom quanto a qualidade dos livros est√£o em per...  amazon\n",
       "496  h√° alguns dias atr√°s adquiri um produto na ama...  amazon\n",
       "497  comecei a leitura hoje e estou abismado com a ...   livro\n",
       "498  concordo com outras avalia√ß√µes feitas entre ou...   livro\n",
       "499  imposs√≠vel ler j√° pedi v√°rias vezes n√£o sei ma...  amazon\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpando a base de dados com todas mensagens:\n",
    "dados_todos = []\n",
    "\n",
    "# Limpeza das mensagens da base de dados de treino\n",
    "for i in range(len(todos_raw)):\n",
    "    mensagem_raw = todos_raw.Mensagem[i]\n",
    "    mensagem = clean(mensagem_raw)\n",
    "    target = todos_raw.Target[i]\n",
    "    \n",
    "    dados_todos.append([mensagem.lower(), target.lower()])\n",
    "    \n",
    "todos = pd.DataFrame(dados_todos, columns=['Mensagem','Target'])\n",
    "\n",
    "todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Criando novo DataFrame com mistura das mensagens:\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "lista_V_pos = []\n",
    "lista_V_neg = []\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    # Cria√ß√£o do novo DataFrame\n",
    "\n",
    "    novo_df = shuffle(todos).copy()\n",
    "    novo_df = novo_df.reset_index(drop=True)\n",
    "    novo_train = novo_df.iloc[0:300,]\n",
    "    novo_test = novo_df.iloc[300:,]\n",
    "    novo_test = novo_test.reset_index(drop=True)\n",
    "    \n",
    "    ######################################\n",
    "    # Lista de todas as palavras\n",
    "\n",
    "    todas_palavras_df = ''\n",
    "\n",
    "    for k in range(len(novo_test.Mensagem)):\n",
    "        msg = str(novo_test.Mensagem[k])\n",
    "        todas_palavras_df += msg + ' '\n",
    "\n",
    "    # Todas as palavras do DataFrame separadas em uma lista\n",
    "    todas_palavras_df = todas_palavras_df.split()\n",
    "\n",
    "    # Series de todas as palavras\n",
    "    serie_df = pd.Series(todas_palavras_df)\n",
    "    tabela_df = serie_df.value_counts()\n",
    "\n",
    "\n",
    "    # Todas as palavras diferentes\n",
    "    palavras_diferentes = len(tabela_df)\n",
    "    \n",
    "\n",
    "    ######################################\n",
    "    # Lista de todas as palavras na categoria Amazon\n",
    "\n",
    "    mensagens_amazon = novo_train.loc[novo_train['Target']=='amazon', ['Mensagem']]\n",
    "    mensagens_amazon = mensagens_amazon.reset_index(drop=True)\n",
    "\n",
    "    todas_palavras_amazon = ''\n",
    "\n",
    "    for l in range(len(mensagens_amazon['Mensagem'])):\n",
    "        msg = str(mensagens_amazon.Mensagem[l])\n",
    "        todas_palavras_amazon += msg + ' '\n",
    "\n",
    "    # Todas as palavras da targer \"amazon\" separadas em uma lista\n",
    "    todas_palavras_amazon = todas_palavras_amazon.split()\n",
    "\n",
    "    # Series de todas as palavras da target \"amazon\"\n",
    "    serie_amazon = pd.Series(todas_palavras_amazon)\n",
    "    tabela_amazon = serie_amazon.value_counts()\n",
    "\n",
    "\n",
    "    # Todas as palavras dentro de amazon\n",
    "    palavras_diferentes_amazon = len(tabela_amazon)\n",
    "    \n",
    "\n",
    "    ######################################\n",
    "    # Lista de todas as palavras na categoria Livros\n",
    "\n",
    "    mensagens_livro = novo_train.loc[novo_train['Target']=='livro', ['Mensagem']]\n",
    "    mensagens_livro = mensagens_livro.reset_index(drop=True)\n",
    "\n",
    "    todas_palavras_livro = ''\n",
    "\n",
    "    for m in range(len(mensagens_livro['Mensagem'])):\n",
    "        msg = str(mensagens_livro.Mensagem[m])\n",
    "        todas_palavras_livro += msg + ' '\n",
    "\n",
    "    # Todas as palavras da target \"livro\" separadas em uma lista\n",
    "    todas_palavras_livro = todas_palavras_livro.split()\n",
    "\n",
    "    # Series de todas as palavras da target \"livro\"\n",
    "    serie_livro = pd.Series(todas_palavras_livro)\n",
    "    tabela_livro = serie_livro.value_counts()\n",
    "\n",
    "\n",
    "    # Todas as palavras dentro de amazon\n",
    "    palavras_diferentes_livro = len(tabela_livro)\n",
    "    \n",
    "\n",
    "    ######################################\n",
    "    # Lista de todas as palavras na categoria Outros\n",
    "\n",
    "    mensagens_outro = novo_train.loc[novo_train['Target']=='outro', ['Mensagem']]\n",
    "    mensagens_outro = mensagens_outro.reset_index(drop=True)\n",
    "\n",
    "    todas_palavras_outro = ''\n",
    "\n",
    "    for n in range(len(mensagens_outro['Mensagem'])):\n",
    "        msg = str(mensagens_outro.Mensagem[n])\n",
    "        todas_palavras_outro += msg + ' '\n",
    "\n",
    "    # Todas as palavras da target \"outro\" separadas em uma lista\n",
    "    todas_palavras_outro = todas_palavras_outro.split()\n",
    "\n",
    "    # Series de todas as palavras da target \"livro\"\n",
    "    serie_outro = pd.Series(todas_palavras_outro)\n",
    "    tabela_outro = serie_outro.value_counts()\n",
    "\n",
    "    \n",
    "    # Todas as palavras dentro de amazon\n",
    "    palavras_diferentes_outro = len(tabela_outro)\n",
    "    \n",
    "    \n",
    "    ######################################\n",
    "    ######################################\n",
    "    \n",
    "    # Loop do classificador\n",
    "    \n",
    "    for j in range(len(novo_test['Mensagem'])):\n",
    "        msg = novo_test.Mensagem[j]\n",
    "        palavras = msg.split()\n",
    "        alpha = 1\n",
    "\n",
    "        amazon_parcial = 1\n",
    "        livro_parcial = 1\n",
    "        outro_parcial = 1\n",
    "\n",
    "        for palavra in palavras:\n",
    "            if palavra not in todas_palavras_amazon:\n",
    "                amazon_parcial *= ((0 + alpha)/(sum(tabela_amazon) + palavras_diferentes))*1000\n",
    "            else:\n",
    "                amazon_parcial *= ((tabela_amazon[palavra] + alpha)/(sum(tabela_amazon) + palavras_diferentes))*1000\n",
    "\n",
    "\n",
    "            if palavra not in todas_palavras_livro:\n",
    "                livro_parcial *= ((0 + alpha)/(sum(tabela_livro) + palavras_diferentes))*1000\n",
    "            else:\n",
    "                livro_parcial *= ((tabela_livro[palavra] + alpha)/(sum(tabela_livro) + palavras_diferentes))*1000\n",
    "\n",
    "\n",
    "            if palavra not in todas_palavras_outro:\n",
    "                outro_parcial *= ((0 + alpha)/(sum(tabela_outro) + palavras_diferentes))*1000\n",
    "            else:\n",
    "                outro_parcial *= ((tabela_outro[palavra] + alpha)/(sum(tabela_outro) + palavras_diferentes))*1000\n",
    "\n",
    "        if outro_parcial > amazon_parcial and outro_parcial > livro_parcial:\n",
    "            novo_test.loc[j, 'Predi√ß√£o'] = 'outro'\n",
    "        elif amazon_parcial > livro_parcial and amazon_parcial > outro_parcial:\n",
    "            novo_test.loc[j, 'Predi√ß√£o'] = 'amazon'\n",
    "        elif livro_parcial > amazon_parcial and livro_parcial > outro_parcial:\n",
    "            novo_test.loc[j, 'Predi√ß√£o'] = 'livro'\n",
    "    \n",
    "    real_x_predicao = pd.crosstab(novo_test['Predi√ß√£o'], novo_test['Target'], normalize = False, margins = True)\n",
    "\n",
    "    # Verdadeiro positivos:\n",
    "    # Mensagens da tag \"AMAZON\", classificadas como \"AMAZON\"\n",
    "    P_V_pos = real_x_predicao['amazon']['amazon']/real_x_predicao['amazon']['All']\n",
    "    lista_V_pos.append(P_V_pos)\n",
    "        \n",
    "    # Verdadeiro negativo:\n",
    "    # Mensagens das tags \"LIVRO\" e \"OUTRO\", classificadas como \"LIVRO\" ou \"OUTRO\"\n",
    "    \n",
    "    # Caso n√£o haja categoria \"OUTRO\" na base de dados TESTE\n",
    "    if 'outro' not in test.Mensagem:\n",
    "        if 'outro' not in test.Predi√ß√£o:\n",
    "            P_V_neg = (real_x_predicao['livro']['livro'] + 0 + 0 + 0)/(real_x_predicao['livro']['All'] + 0)\n",
    "        else:\n",
    "            P_V_neg = (real_x_predicao['livro']['livro'] + 0 + real_x_predicao['livro']['outro'] + 0)/(real_x_predicao['livro']['All'] + 0)\n",
    "    \n",
    "    else:\n",
    "        if 'outro' not in test.Predi√ß√£o:\n",
    "            P_V_neg = (real_x_predicao['livro']['livro'] + real_x_predicao['outro']['livro'] + 0 + 0)/(real_x_predicao['livro']['All'] + real_x_predicao['outro']['All'])\n",
    "        else:\n",
    "            P_V_neg = (real_x_predicao['livro']['livro'] + real_x_predicao['outro']['livro'] + real_x_predicao['livro']['outro'] + real_x_predicao['outro']['outro'])/(real_x_predicao['livro']['All'] + real_x_predicao['outro']['All'])\n",
    "\n",
    "    lista_V_neg.append(P_V_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(lista_V_pos, bins=20, color='b', edgecolor='white', density=True, alpha=0.6)\n",
    "plt.ylim(0,20)\n",
    "plt.xlim(0.5,1)\n",
    "plt.title(\"Porcentagem de Verdadeiros Positivos\")\n",
    "plt.xlabel('Probabilidade de Verdadeiro Positivo [%]')\n",
    "plt.ylabel('Densidade')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(lista_V_neg, bins=20, color='r', edgecolor='white', density=True, alpha=0.6)\n",
    "plt.ylim(0,20)\n",
    "plt.xlim(0.5,1)\n",
    "plt.title('Porcentagem de Verdadeiros Negativos')\n",
    "plt.xlabel('Probabilidade de Verdadeiro Negativos [%]')\n",
    "plt.ylabel('Densidade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lista_V_pos, color='b', edgecolor='white', density=True, alpha=0.6, label='Verdadeiro positivo')\n",
    "plt.hist(lista_V_neg, color='r', edgecolor='white', density=True, alpha=0.6, label='Verdadeiro negativo')\n",
    "plt.legend()\n",
    "plt.title(\"Porcentagem de 'Verdadeiros positivos' e 'Verdadeiros negativos'\")\n",
    "plt.xlabel('Probabilidade')\n",
    "plt.ylabel('Densidade')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste histograma podemos observar que a quantidade de verdadeiros positivos (cor azul) est√° mais concentrada √† direita do gr√°fico, o que indica uma maior acur√°cia do nosso classificador em definir como \"AMAZON\" tags que realmente s√£o \"AMAZON\". J√° no caso de verdadeiros negativos (cor vermelha), ou seja, mensagens que nosso classificador definiu como \"LIVRO\" ou \"OUTRO\", tags que originalmente eram \"LIVRO\" ou \"OUTRO\", est√° mais deslocada para a esquerda, apresentando um menor acerto nesses casos. (Provavelmente, devido √† separa√ß√£o de verdadeiro negativo em duas tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na vari√°vel Target e INCREMENTOU a quantidade de not√≠cias, mantendo pelo menos 250 not√≠cias por categoria (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto (pelo menos dois cen√°rios, exceto aqueles j√° apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separa√ß√µes das Not√≠cias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que n√£o podemos utilizar o classificador para gerar mais amostras de treinamento:\n",
    "\n",
    "1 - O classificador inicial pode ter algum tipo de limita√ß√£o ou vi√©s. Esses problemas fariam com que a gera√ß√£o de novas amostras sejam problem√°ticas, o que levaria a uma perpetua√ß√£o do erro.\n",
    "\n",
    "2 - Possibilidade de novas amostras serem iguais √†s originais, o que implicaria numa falta de diversidade de palavras para ele aprender. Tornando a an√°lise de novos textos muito dif√≠cil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferentes cen√°rios para Na√Øve Bayes\n",
    "\n",
    "1 - Detec√ß√£o de transa√ß√µes suspeitas em contas de bancos com base na atividade dessas contas;\n",
    "\n",
    "2 - Detec√ß√£o de doen√ßas em hospitais com base nos sintomas;\n",
    "\n",
    "3 - Direcionamento de an√∫ncios baseado no tipo de busca do usu√°rio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhorias reais com indica√ß√µes concretas de como implementar\n",
    "\n",
    "1 - Pr√©-processamento de texto de qualidade:\n",
    "\n",
    "- Remo√ß√£o de stop-words: As stop words s√£o palavras que n√£o agregam informa√ß√£o crucial para as frases (s√£o utilizadas para tornar a escrita em algo mais natural e fluido). Alguns exemplos de stop words em portugu√™s s√£o: 'em', 'para', 'da', 'que', 'o' e assim por diante. A remo√ß√£o dessas palavras da frase, a torna mais objetiva o que, dependendo do caso, pode resultar em uma an√°lise mais fiel e correta da mensagem original; \n",
    "\n",
    "    - Um exemplo de remo√ß√£o de stop-words: \n",
    "        \n",
    "        \"Ao caminhar pelo parque, observei muitos p√°ssaros pequenos voando entre as √°rvores.\" | Com stop-words \n",
    "        \n",
    "        \"Caminhar parque, observei p√°ssaros pequenos voando √°rvores.\" | Sem stop-words\n",
    "        \n",
    "    - Fonte: https://towardsdatascience.com/text-pre-processing-stop-words-removal-using-different-libraries-f20bac19929a\n",
    "\n",
    "<br>\n",
    "        \n",
    "- Lemmatization: A lematiza√ß√£o √© o processo de agrupar diferentes formas flexionadas da mesma palavra em lemas, ou seja, uma forma reduzida. Por esse m√©todo, as plavras \"corrida\", \"correndo\", \"correu\" e \"corre\" seriam reduzidas ao lema \"correr\", o que simplificaria a an√°lise do texto.\n",
    "\n",
    "    - Fonte: https://www.techtarget.com/searchenterpriseai/definition/lemmatization#:~:text=Lemmatization%20is%20the%20process%20of,processing%20(NLP)%20and%20chatbots.\n",
    "\n",
    "\n",
    "2 - Balanceamento das classes target:\n",
    "\n",
    "- Uma outra forma de melhorar a an√°lise do classificador, seria fazendo um balanceamento melhor das targets classificadas. Isso poderia ser feito atrav√©s de m√©todos de oversampling da target com menos informa√ß√µes ou undersampling da target com mais informa√ß√µes.\n",
    "\n",
    "- Esses passos poderiam ser feitos de forma rand√¥mica (existem bibliotecas no Python para isso) em que deve-se duplicar aleatoriamente a target minorit√°ria para atingir um n√∫mero equilibrado de targets, ou excluir, tamb√©m aleat√≥riamente, mensagens da target majorit√°ria at√© atingir o equil√≠brio.\n",
    "\n",
    "    - Fonte: https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
